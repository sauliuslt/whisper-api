# Whisper Model Configuration
WHISPER_MODEL=large-v3  # Options: tiny, base, small, medium, large, large-v2, large-v3
WHISPER_DEVICE=cuda     # Options: cuda, cpu
WHISPER_COMPUTE_TYPE=float16  # Options: float16, float32, int8

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1  # Keep at 1 for GPU to avoid memory issues
MAX_AUDIO_FILE_SIZE_MB=25
ALLOWED_AUDIO_FORMATS=mp3,mp4,mpeg,mpga,m4a,wav,webm,flac,ogg

# GPU Configuration
CUDA_VISIBLE_DEVICES=0  # GPU device ID
GPU_MEMORY_FRACTION=0.9  # Fraction of GPU memory to use

# Performance
ENABLE_MODEL_CACHE=true
MODEL_CACHE_DIR=/app/models
BATCH_SIZE=1  # Increase if you have enough GPU memory
NUM_WORKERS=4  # For data loading

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json